name: Daily Beer Price Tracker

on:
  schedule:
    - cron: '0 6 * * *' # T√§glich 6 Uhr
  workflow_dispatch:

permissions:
  contents: write
  pages: write      # WICHTIG f√ºr GitHub Pages
  id-token: write   # WICHTIG f√ºr GitHub Pages

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    
    steps:
      # 1. Code holen
      - name: Checkout code
        uses: actions/checkout@v4

      # 2. Python installieren
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      # 3. Abh√§ngigkeiten (jetzt mit jinja2)
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi

      # 4. Scraper laufen lassen (holt preise.json)
      - name: Run Scraper
        env:
          NETTO_COOKIE: ${{ secrets.NETTO_COOKIE }}
        run: python src/main.py

      # 5. Webseite bauen (baut public/index.html aus preise.json)
      - name: Build Website
        run: python src/build_site.py

      # 6. Daten (JSON) ins Repo committen (optional, falls du Historie willst)
      - name: Commit data changes
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "üç∫ Update Data"
          file_pattern: 'data/*.json'

      # 7. Webseite auf GitHub Pages hochladen
      - name: Upload artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: 'public' # Wir laden nur den 'public' Ordner hoch

      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
